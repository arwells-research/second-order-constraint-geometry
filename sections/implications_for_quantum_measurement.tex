\section{Implications for Quantum Measurement}
\label{sec:implications-quantum-measurement}

Quantum measurement is often regarded as the most persistent conceptual difficulty
in quantum theory because it appears to introduce a directional asymmetry that is
absent from the underlying dynamical laws. Measurements occur, outcomes are
recorded, and superpositions do not spontaneously reappear, even though unitary
quantum dynamics are time-reversal symmetric. This section clarifies the structural
origin of this asymmetry within the present framework.

The present work does not propose a collapse mechanism, modify unitary dynamics, or
introduce hidden variables. It addresses a narrower question: why measurement
exhibits arrow-like behavior even when the admissible dynamics themselves are
symmetric.

Within second-order constraint geometry, measurement is understood as the
imposition of a conditioning boundary. A measurement interaction and outcome
registration restrict which future histories remain admissible, independently of
the form of the underlying dynamics. This restriction is not representable as a
property of the instantaneous post-measurement quantum state. Once the boundary is
imposed, admissibility depends on the ordered sequence of events rather than on the
state alone.

From this perspective, the apparent irreversibility of measurement does not arise
from a dynamical prohibition against reversal. It arises because, after a
measurement boundary has been imposed, histories in which the outcome is undone are
no longer admissible under the operational constraints. Their exclusion follows
from admissibility structure rather than from any intrinsic time asymmetry in the
laws of motion.

This classification explains why measurement irreversibility is robust across
interpretations. Whether one adopts collapse models, many-worlds, or decoherence,
the operational asymmetry persists because it reflects a loss of state sufficiency
once history-dependent constraints are imposed. The asymmetry is therefore not an
interpretive artifact but a structural feature of admissible histories.

Decoherence fits naturally into this picture. Decoherence suppresses interference
between branches by projecting onto a reduced description relative to an
environmental partition. It does not, by itself, select a unique outcome. The
arrow-like behavior associated with decoherence arises when this projection is
combined with boundary selection that restricts admissible continuations. In this
sense, decoherence explains why certain superpositions become operationally
inaccessible, while second-order constraint geometry explains why accessibility
itself becomes history-dependent.

Measurement records are best understood not as stored states but as constraints on
future admissibility. Once a record exists, future operations must be consistent
with it. This is why arrow-like behavior appears even in minimal measurement-like
interactions, such as single-photon detection, post-selection, or weak measurement.
The macroscopic character of records is incidental; what matters is the imposition
of a second-order constraint on admissible histories.

Objective collapse models introduce explicit time-asymmetric dynamics in order to
account for measurement irreversibility. Within the present taxonomy, such models
address the problem by modifying the dynamics themselves. The approach developed
here neither endorses nor refutes these models. It clarifies that measurement
asymmetry can be understood without invoking intrinsic dynamical asymmetry, by
recognizing that measurement alters admissibility rather than state alone.

The contribution of the $\Sigma_2$ framework is therefore not a solution to the
measurement problem in the strong sense. It explains why the problem takes the form
it does. Measurement appears asymmetric because it changes the space of admissible
futures, and once this change occurs, no state-based description can fully encode
what has been excluded.