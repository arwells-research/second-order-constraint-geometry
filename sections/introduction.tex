\section{Introduction}

Modern physics is extraordinarily successful at predicting experimental outcomes,
yet persistent conceptual tensions remain concerning the sufficiency of
state-based descriptions. In particular, many physical situations exhibit dependence on preparation order or history, even when the instantaneous physical state (whether phase-space point, state vector, or density operator) is identical. Such cases are typically treated as interpretational subtleties,
contextual effects, or artifacts of coarse-graining. In this work we argue that
they instead indicate a distinct and under-articulated structural feature of
physical theory: the existence of constraints that act on \emph{admissible
histories} rather than on instantaneous states.

Standard physical formalisms are fundamentally first-order in this sense. They
specify a space of states together with dynamical laws governing transitions
between them. Given a state (and possibly a probability distribution over states),
future evolution is assumed to be fully determined, up to stochasticity encoded
within the formalism itself. When apparent violations of state sufficiency arise,
the usual response is to enlarge the state description---for example by adding
hidden variables, environmental degrees of freedom, memory registers, or
conditioning labels. While such augmentations can restore formal determinism,
they often do so at the cost of introducing nonlocality, ad hoc bookkeeping, or
structures that lack independent physical motivation. From this perspective,
non-Markovian and memory-augmented models are not alternatives to state
sufficiency, but evidence of its failure: they succeed precisely by relocating
admissibility constraints from state to history. Second-order constraint geometry
is not assumed to be universally present, but is diagnostically invoked only where
state sufficiency demonstrably fails.

This paper proposes an alternative perspective. We introduce the notion of
\emph{second-order constraint geometry}, denoted $\Sigma_2$, which formalizes
constraints defined not on states but on trajectories, orderings, and admissible
sequences of transformations. The central claim is not that state-based theories
are incorrect, but that they are sometimes \emph{insufficient}: there exist
physically relevant distinctions that cannot be captured by instantaneous state
alone, even when the state description is exact. In such cases, the relevant
structure resides at the level of admissible histories, and must be represented
geometrically rather than dynamically.

The $\Sigma_2$ framework does not modify underlying equations of motion, introduce
new forces, or posit hidden variables. Instead, it provides a minimal formal
language for describing when and how history-dependent constraints arise, how
they can be diagnosed operationally, and under what conditions they are
empirically distinguishable from first-order (state-based) effects. In this
sense, $\Sigma_2$ plays a role analogous to other structural frameworks in
foundations: it restricts the space of admissible explanations without proposing
a specific mechanism for every phenomenon it classifies. Second-order constraint geometry is not proposed as a universal feature of physical systems, but as a diagnostic language applicable only in regimes where no faithful state-based representation exists. Second-order constraint geometry is therefore classificatory rather than mechanistic: it identifies representational boundaries without introducing new dynamical postulates.

The motivation for this work is closely related to, but distinct from, recent
analyses of arrow-like directedness and irreversibility. In a companion paper,
we showed that arrow-like diagnostics cannot arise intrinsically from symmetric
admissible dynamics under boundary-symmetric operational reduction, and must
instead be boundary-radial features of reduced descriptions. That result was
intentionally non-constructive: it classified the locus of asymmetry without
explaining why certain physical situations require conditioning boundaries or
ordering sensitivity in the first place. The present work addresses this missing
piece. We ask not where arrows come from, but why certain physical descriptions
cease to be state-sufficient at all.

Within this framework, many familiar puzzles---including measurement versus
post-selection asymmetries, environment-induced decoherence, and preparation-order
effects---can be reinterpreted as manifestations of second-order constraints.
Crucially, these effects do not require rejecting standard quantum mechanics, nor
do they imply that the theory is “wrong.” Rather, they highlight that the quantum
formalism, like any first-order state-based theory, is silent about certain
history-level distinctions unless additional structure is supplied. $\Sigma_2$
provides a way to make such structure explicit without altering the core dynamics.

The paper proceeds as follows. We begin by clarifying the limits of first-order
(state-based) sufficiency and identifying the minimal conditions under which
history dependence becomes unavoidable. We then introduce the formal definition
of second-order constraint geometry and develop diagnostic criteria for identifying
$\Sigma_2$ effects in practice. Several toy examples and case studies are used to
illustrate how $\Sigma_2$ constraints arise in measurement, post-selection, and
environmental coupling scenarios. We next articulate falsifiability conditions
and propose a concrete experimental protocol capable of distinguishing $\Sigma_2$
effects from state-augmented first-order explanations. We conclude by discussing
the implications of this framework for quantum foundations, no-go theorems, and
the interpretation of irreversibility, while emphasizing the deliberately limited
scope of the present claims.

Crucially, the framework’s core existence claim is demonstrated via a fully worked
example (Sec.~\ref{subsec:concrete-hamiltonian-example} and Appendix~\ref{app:hamiltonian-derivation}) featuring
explicit Hamiltonians and an operationally defined symmetry group. This example
establishes that the identified representational limitations are physically
realizable within standard unitary quantum mechanics, rather than being artifacts
of abstraction or coarse-graining.

Throughout, our aim is methodological rather than revisionary. We do not seek to
replace existing physical theories, but to clarify the conditions under which they
are sufficient, and to provide a principled geometric framework for describing
the cases in which they are not. We distinguish \emph{predictive sufficiency}
(fixing outcome statistics) from \emph{admissibility sufficiency} (fixing which
future operations remain physically possible), and show that the latter can fail
even when the former holds.